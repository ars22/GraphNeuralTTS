{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from src.dataset_hrg import getDataLoader\n",
    "from src.module_hrg import EmbeddingHRG\n",
    "from torch_geometric.data.batch import Batch\n",
    "from torch.optim import AdamW\n",
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classifier\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DurationClassifier(torch.nn.Module):\n",
    "    def __init__(self, h_dim, n_buckets):\n",
    "        super(DurationClassifier, self).__init__()\n",
    "        self.gcn = EmbeddingHRG(data_tr.dataset.n_vocab, self.h_dim, self.h_dim).cuda()\n",
    "        self.n_buckets = n_buckets\n",
    "        self.h_dim = h_dim\n",
    "        self.cls_head = nn.Sequential(nn.Linear(self.h_dim, self.h_dim // 2),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Linear(self.h_dim // 2, self.n_buckets))\n",
    "    def forward(self, x):\n",
    "        x = self.gcn(x)\n",
    "        return self.cls_head(x)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open(\"config/config-arctic.yaml\", 'r'), Loader=yaml.FullLoader)\n",
    "_config = config['solver']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tr = getDataLoader(\n",
    "    mode='train',\n",
    "    meta_path=_config['meta_path']['train'],\n",
    "    data_dir=_config['data_dir'],\n",
    "    batch_size=_config['batch_size'],\n",
    "    r=config['model']['tacotron']['r'],\n",
    "    n_jobs=_config['n_jobs'],\n",
    "    use_gpu=True,\n",
    "    add_info_headers=[\"dur\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_buckets = 11\n",
    "h_dim = 256\n",
    "label_dict = {f\"DB_{i}\": i for i in range(n_buckets)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Init the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dur_classifier = DurationClassifier(h_dim=h_dim, n_buckets=n_buckets).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = AdamW(dur_classifier.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_labels(label_seq):\n",
    "    label_seq = [ls.strip().split() for ls in label_seq]\n",
    "    res = []\n",
    "    for ls in label_seq:\n",
    "        res.append([label_dict[x] for x in ls])\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f = nn.CrossEntropyLoss(ignore_index=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in data_tr:\n",
    "    # for a batch, run GCN\n",
    "    _, txt, text_lengths, mel, spec, add_info = batch\n",
    "    add_info = parse_labels(add_info)\n",
    "    output = model(txt)\n",
    "    bsz, max_nodes, hsz = output.shape; bsz, max_nodes, hsz\n",
    "    \n",
    "    # duration classification\n",
    "    class_output = dur_classifier(output); \n",
    "    \n",
    "    # get a representation for the syll nodes\n",
    "    syll_dur = torch.zeros(len(add_info), max_nodes).long() - 1\n",
    "    for i in range(len(add_info)):\n",
    "        syll_dur[i, :len(add_info[i])] = torch.LongTensor(add_info[i])\n",
    "    loss_val = loss_f(class_output.view(-1, n_buckets), syll_dur.view(-1).cuda())\n",
    "    print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_all = pd.read_csv(\"arctic/meta_all.txt\", sep=\"|\", names=[\"mel\", \"lin\", \"len\", \"hrg\", \"add_info\"])\n",
    "meta_all = meta_all.drop(labels=\"add_info\", axis=1)\n",
    "syll_dur = pd.read_csv(\"syll_dur_end.txt\", sep=\"|\", names=[\"source\", \"target\", \"end\"])\n",
    "merged = pd.concat([meta_all, syll_dur], axis=1)\n",
    "merged[[\"mel\", \"lin\", \"len\", \"hrg\", \"target\"]].to_csv(\"arctic/meta_all.txt\", sep=\"|\", header=False, index=None)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
