{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scripts to analyze audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASEDIR=\"/usr2/asetlur/GraphNeuralTTS/Tacotron-pytorch/training-accentdb-char-baseline-with-additional-info/\"\n",
    "LOGDIR=\"log\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mel-spectogram classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import glob\n",
    "import os\n",
    "from collections import Counter\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataloader/Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_2d(x, max_len):\n",
    "    x = np.pad(x, [(0, max_len - len(x)), (0, 0)],\n",
    "               mode=\"constant\", constant_values=0)\n",
    "    return x\n",
    "\n",
    "class MelDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, pth):\n",
    "        self.mel_files = glob.glob(f\"{BASEDIR}/*mel*\")\n",
    "        print(f\"{len(self.mel_files)} mel-files found\")\n",
    "        # the files are supposed to be named accent_speaker_*.wav, \n",
    "        # e.g. australian_s02_362.wav\n",
    "        self.labels = [os.path.basename(mel_file_pth).split(\"_\")[:2] for mel_file_pth in self.mel_files]\n",
    "        labels = [os.path.basename(mel_file_pth).split(\"_\")[:2] for mel_file_pth in self.mel_files]\n",
    "        \n",
    "        # get accent labels, make a dict\n",
    "        self.accent_labels = [l[0] for l in self.labels]\n",
    "        self.accent_label_dict = {k: i for i, k in enumerate(sorted(Counter(self.accent_labels).keys()))}\n",
    "        print(self.accent_label_dict)\n",
    "        \n",
    "        # same processing for the speakers\n",
    "        self.speaker_labels = [\" \".join(l) for l in self.labels]\n",
    "        self.speaker_label_dict = {k: i for i, k in enumerate(sorted(Counter(self.speaker_labels).keys()))}\n",
    "        print(self.speaker_label_dict)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return np.load(self.mel_files[i])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.mel_files)\n",
    "\n",
    "    @staticmethod\n",
    "    def batchify(dataset, bsz, shuffle=True):\n",
    "        idx = list(range(len(dataset)))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(idx)\n",
    "\n",
    "        for begin in range(0, len(dataset), bsz):\n",
    "            end = min(begin + bsz, len(dataset))\n",
    "            num_elems = end - begin\n",
    "    \n",
    "            \n",
    "            # read all the mels for this batch, find the max length\n",
    "            mels = [dataset[idx[i]] for i in range(begin, end)]\n",
    "            seq_lengths = torch.LongTensor([len(mel) for mel in mels])\n",
    "            max_target_len = seq_lengths.max().item()\n",
    "            \n",
    "            \n",
    "            b = np.array([_pad_2d(mel, max_target_len) for mel in mels],\n",
    "                 dtype=np.float32)\n",
    "            mel_batch = torch.FloatTensor(b)\n",
    "            speaker_labels = torch.LongTensor([dataset.speaker_label_dict[dataset.speaker_labels[idx[i]]]\\\n",
    "                                               for i in range(begin, end)])\n",
    "            accent_labels = torch.LongTensor([dataset.accent_label_dict[dataset.accent_labels[idx[i]]]\\\n",
    "                                              for i in range(begin, end)])\n",
    "            \n",
    "            \n",
    "            seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)\n",
    "            \n",
    "            \n",
    "            yield mel_batch[perm_idx], speaker_labels[perm_idx], accent_labels[perm_idx], seq_lengths\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14999 mel-files found\n",
      "{'american': 0, 'australian': 1, 'bangla': 2, 'british': 3, 'indian': 4, 'malayalam': 5, 'odiya': 6, 'telugu': 7, 'welsh': 8}\n",
      "{'american s01': 0, 'american s02': 1, 'american s03': 2, 'american s04': 3, 'american s05': 4, 'american s06': 5, 'american s07': 6, 'american s08': 7, 'australian s01': 8, 'australian s02': 9, 'bangla s01': 10, 'bangla s02': 11, 'british s01': 12, 'british s02': 13, 'indian s01': 14, 'indian s02': 15, 'malayalam s01': 16, 'malayalam s02': 17, 'malayalam s03': 18, 'odiya s01': 19, 'telugu s01': 20, 'telugu s02': 21, 'welsh s01': 22}\n",
      "(154, 80)\n",
      "torch.Size([32, 379, 80]) torch.Size([32]) torch.Size([32])\n",
      "torch.Size([32, 437, 80]) torch.Size([32]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# dataset sanity checks\n",
    "dataset = MelDataset(BASEDIR)\n",
    "\n",
    "# check shape of one mel file\n",
    "print(dataset[0].shape)\n",
    "\n",
    "# dataloader check\n",
    "dataloader = MelDataset.batchify(dataset, 32)\n",
    "\n",
    "# check two batches for correct batchification:\n",
    "for _ in range(2):\n",
    "    mel, speaker, accent, input_lengths = next(dataloader)\n",
    "    print(mel.shape, speaker.shape, accent.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1dconv(in_channels, out_channels, max_pool=False):\n",
    "    return nn.Sequential(nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1),\n",
    "                      nn.ELU(),\n",
    "                      nn.BatchNorm1d(out_channels),\n",
    "                      nn.MaxPool1d(3, stride=2) if max_pool else nn.Identity(),\n",
    "                      nn.Dropout(p=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelClassifier(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_class,\n",
    "                 mel_spectogram_dim: int = 80,\n",
    "                 gru_hidden_size=32,\n",
    "                 gru_num_layers=2):\n",
    "        super(MelClassifier, self).__init__()\n",
    "        self.num_class = num_class\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "                        get_1dconv(in_channels=mel_spectogram_dim, out_channels=64),\n",
    "                        get_1dconv(in_channels=64, out_channels=128),\n",
    "                        get_1dconv(in_channels=128, out_channels=128, max_pool=True),\n",
    "                        get_1dconv(in_channels=128, out_channels=128, max_pool=True),\n",
    "                        get_1dconv(in_channels=128, out_channels=128, max_pool=True))\n",
    "            \n",
    "        self.gru = nn.GRU(input_size=128, hidden_size=gru_hidden_size, num_layers=gru_num_layers,\\\n",
    "                          bidirectional=True, batch_first=True, dropout=0.3)\n",
    "        num_directions = 2\n",
    "        self.mlp = nn.Linear(gru_hidden_size * gru_num_layers * num_directions, self.num_class)\n",
    "\n",
    "    def forward(self, mel_batch, input_lengths):\n",
    "        batch_size = len(mel_batch)\n",
    "        # mel_batch -> (batch_size, max_time_step, 80)\n",
    "        conv_output = self.conv_blocks(mel_batch.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "        # conv_output -> (batch_size, max_time_step, 32)\n",
    "\n",
    "        output, h_n = self.gru(conv_output)\n",
    "        # h_n -> (4, batch_size, 32)\n",
    "        \n",
    "        h_n = h_n.permute(1, 0, 2).reshape(batch_size, -1)\n",
    "        return h_n, self.mlp(h_n)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MelClassifier(len(dataset.speaker_label_dict)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3,\n",
    "                                    betas=(0.9, 0.99),\n",
    "                                    eps=1e-6,\n",
    "                                    weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(LOGDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.call([\"rm\", \"-r\", f\"{LOGDIR}/*\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14999 mel-files found\n",
      "{'american': 0, 'australian': 1, 'bangla': 2, 'british': 3, 'indian': 4, 'malayalam': 5, 'odiya': 6, 'telugu': 7, 'welsh': 8}\n",
      "{'american s01': 0, 'american s02': 1, 'american s03': 2, 'american s04': 3, 'american s05': 4, 'american s06': 5, 'american s07': 6, 'american s08': 7, 'australian s01': 8, 'australian s02': 9, 'bangla s01': 10, 'bangla s02': 11, 'british s01': 12, 'british s02': 13, 'indian s01': 14, 'indian s02': 15, 'malayalam s01': 16, 'malayalam s02': 17, 'malayalam s03': 18, 'odiya s01': 19, 'telugu s01': 20, 'telugu s02': 21, 'welsh s01': 22}\n",
      "Epoch = 0 iter = 0 Loss = 0.15 Acc = 100.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-df087ae16975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mh_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeakers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mspeakers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr2/asetlur/anaconda3/envs/nmt/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-2d9be3c861c7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, mel_batch, input_lengths)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# conv_output -> (batch_size, max_time_step, 32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;31m# h_n -> (4, batch_size, 32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr2/asetlur/anaconda3/envs/nmt/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr2/asetlur/anaconda3/envs/nmt/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 735\u001b[0;31m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    736\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "dataset = MelDataset(BASEDIR)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "losses = []\n",
    "accuracy = []\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    dataloader = MelDataset.batchify(dataset, 32)\n",
    "    \n",
    "    # training\n",
    "    for i, (mels, speakers, accents, input_lengths) in enumerate(dataloader):\n",
    "        mels = mels.to(device)\n",
    "        speakers = speakers.to(device)\n",
    "        accents = accents.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        h_n, logits = model(mels, input_lengths)\n",
    "        loss = loss_func(logits, speakers).mean()\n",
    "        accuracy.append(sum(torch.argmax(logits, dim=1) == speakers).item() * 100. / len(accents))\n",
    "    \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        if i % 50 == 0:\n",
    "            print(f\"Epoch = {epoch} iter = {i} Loss = {round(np.array(losses).mean(), 2)} Acc = {round(np.array(accuracy).mean(), 2)}\")\n",
    "            losses = []\n",
    "            \n",
    "    metadata_speaker = []\n",
    "    metadata_accent = []    \n",
    "    dataloader = MelDataset.batchify(dataset, 32)\n",
    "\n",
    "    # extract embedding for tboard\n",
    "    print(\"Extracting Embedding\")\n",
    "    for i, (mels, speakers, accents, input_lengths) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "\n",
    "        metadata_accent += speakers.numpy().tolist()\n",
    "        metadata_accent += accents.numpy().tolist()\n",
    "        mels = mels.to(device)\n",
    "        speakers = speakers.to(device)\n",
    "        accents = accents.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            h_n, logits = model(mels, input_lengths)\n",
    "            writer.add_embedding(tag=\"accent\",\n",
    "                                mat=h_n,\n",
    "                                global_step=epoch,\n",
    "                                metadata=metadata_accent)\n",
    "            writer.add_embedding(tag=\"speaker\",\n",
    "                    mat=h_n,\n",
    "                    global_step=epoch,\n",
    "                    metadata=metadata_speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/468 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Embedding\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "#labels should equal with #data points",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-3a8e9f83506a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                             \u001b[0mmat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh_n\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                             \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                             metadata=metadata_accent)\n\u001b[0m\u001b[1;32m     18\u001b[0m         writer.add_embedding(tag=\"speaker\",\n\u001b[1;32m     19\u001b[0m                 \u001b[0mmat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh_n\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr2/asetlur/anaconda3/envs/nmt/lib/python3.7/site-packages/tensorboardX/writer.py\u001b[0m in \u001b[0;36madd_embedding\u001b[0;34m(self, mat, metadata, label_img, global_step, tag, metadata_header)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             assert mat.shape[0] == len(\n\u001b[0;32m--> 779\u001b[0;31m                 metadata), '#labels should equal with #data points'\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0mmake_tsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlabel_img\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: #labels should equal with #data points"
     ]
    }
   ],
   "source": [
    "print(\"Extracting Embedding\")\n",
    "dataloader = MelDataset.batchify(dataset, 32)\n",
    "\n",
    "\n",
    "for i, (mels, speakers, accents, input_lengths) in tqdm(enumerate(dataloader), total=len(dataset) // 32):\n",
    "    \n",
    "    metadata_accent += speakers.numpy().tolist()\n",
    "    metadata_accent += accents.numpy().tolist()\n",
    "    mels = mels.to(device)\n",
    "    speakers = speakers.to(device)\n",
    "    accents = accents.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        h_n, logits = model(mels, input_lengths)\n",
    "        \n",
    "writer.add_embedding(tag=\"accent\",\n",
    "                    mat=h_n,\n",
    "                    global_step=epoch,\n",
    "                    metadata=metadata_accent)\n",
    "writer.add_embedding(tag=\"speaker\",\n",
    "        mat=h_n,\n",
    "        global_step=epoch,\n",
    "        metadata=metadata_speaker)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
